{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pycld2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the text\n",
    "def clean(text):\n",
    "    # Removes all special characters and numericals leaving the alphabets\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    text = re.sub('httpS+s*', ' ',text)  # remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub('RT|cc', ' ', text)  # remove RT and cc\n",
    "    text = re.sub('#S+', '', text)  # remove hashtags\n",
    "    text = re.sub('@S+', '  ', text)  # remove mentions\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[]^_`{|}~\"\"\"), ' ', text)  # remove punctuations\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',r' ', text) # replace non-ASCII characters\n",
    "    text = re.sub('\\s\\s+', ' ', text)  # remove extra whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycld2 as cld2\n",
    "def langdetect(text):\n",
    "    vectors = cld2.detect(text, returnVectors=True)\n",
    "    vectors = str(vectors)\n",
    "    return(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "      if word.lower() not in set(stopwords.words('english')):\n",
    "        newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment analysis using TextBlob\n",
    "from textblob import TextBlob\n",
    "# function to calculate subjectivity\n",
    "def getSubjectivity(review):\n",
    "    return TextBlob(review).sentiment.subjectivity\n",
    "# function to calculate polarity\n",
    "def getPolarity(review):\n",
    "    return TextBlob(review).sentiment.polarity\n",
    "\n",
    "# function to analyze the reviews\n",
    "def analysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_graph(df):\n",
    "    df['Text_Blob'].value_counts().plot.bar(colormap='Pastel1')\n",
    "    return plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def cloud_per(df):\n",
    "    fig = plot.figure(figsize=(30, 25))\n",
    "    for i, sentiment in enumerate(['Positive', 'Neutral', 'Negative']):\n",
    "        compound_text_dif = \" \".join(text for text in df[df.Text_Blob == sentiment].text)\n",
    "        compound_wc_dif = WordCloud(background_color=\"white\", max_words=100, width = 2000, height = 600).generate(compound_text_dif)\n",
    "        fig.add_subplot(3, 3, i+1)\n",
    "        plot.imshow(compound_wc_dif, interpolation='bilinear')\n",
    "        plot.axis(\"off\")\n",
    "    return plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipyupload\n",
    "#!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "#!jupyter serverextension enable voila --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Widget\n",
    "\n",
    "file = open(\"slu.png\", \"rb\")\n",
    "image = file.read()\n",
    "\n",
    "image_headline = widgets.Image(\n",
    "                    value=image,\n",
    "                    format='png',\n",
    "                    width='100'\n",
    "                )\n",
    "\n",
    "\n",
    "vbox_headline = widgets.VBox([image_headline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file\n",
    "file = widgets.FileUpload(\n",
    "    accept='.csv',  \n",
    "    multiple=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = widgets.ToggleButtons(\n",
    "            options=['English', 'Tagalog']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# button send\n",
    "from IPython.display import HTML\n",
    "\n",
    "button_send = widgets.Button(\n",
    "                description='Classify',\n",
    "                tooltip='Classify',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "output = widgets.Output()\n",
    "bar = widgets.Output()\n",
    "cloud = widgets.Output()\n",
    "\n",
    "def on_button_clicked(event):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        input_file = list(file.value.values())[0]\n",
    "        content = input_file['content']\n",
    "        comments = io.StringIO(content.decode('utf-8'))\n",
    "        df = pd.read_csv(comments)\n",
    "        df.columns=['Text']\n",
    "        tagalogdf = pd.DataFrame(columns=['text'])\n",
    "        englishdf = pd.DataFrame(columns=['text'])\n",
    "        df['Cleaned_Text'] = df['Text'].apply(clean)\n",
    "        df.drop('Text', inplace=True, axis=1)\n",
    "        display(df.style.set_properties(**{'background-color': 'lightblue',                                     \n",
    "                                    'color': 'black',               \n",
    "                                    'border-color': 'black'}))\n",
    "        df['Lang_Detect'] = df['Cleaned_Text'].apply(langdetect)\n",
    "        tagalog = df.loc[df['Lang_Detect'].str.contains(\"tagalog\", case=False)]\n",
    "        english = df.loc[df['Lang_Detect'].str.contains(\"english\", case=False)]\n",
    "        tagalogdf['text'] = tagalog['Cleaned_Text']\n",
    "        englishdf['text'] = english['Cleaned_Text']\n",
    "        tagalogdf['POS tagged'] = tagalogdf['text'].apply(token_stop_pos)\n",
    "        englishdf['POS tagged'] = englishdf['text'].apply(token_stop_pos)\n",
    "        tagalogdf['Lemma'] = tagalogdf['POS tagged'].apply(lemmatize)\n",
    "        englishdf['Lemma'] = englishdf['POS tagged'].apply(lemmatize)\n",
    "        #Create Data Frame\n",
    "        global tgl_classified\n",
    "        global eng_classified\n",
    "        tgl_classified = pd.DataFrame()\n",
    "        eng_classified = pd.DataFrame()\n",
    "        #Tagalog\n",
    "        tgl_classified = tagalogdf.copy()\n",
    "        tgl_classified['Text_Blob Polarity'] = tgl_classified['Lemma'].apply(getPolarity) \n",
    "        tgl_classified['Text_Blob'] = tgl_classified['Text_Blob Polarity'].apply(analysis)\n",
    "        #English\n",
    "        eng_classified= englishdf.copy()\n",
    "        eng_classified['Text_Blob Polarity'] = eng_classified['Lemma'].apply(getPolarity) \n",
    "        eng_classified['Text_Blob'] = eng_classified['Text_Blob Polarity'].apply(analysis)\n",
    "def changed(change):\n",
    "    with cloud:\n",
    "        cloud.clear_output()\n",
    "        if lang.value ==  'English':\n",
    "            cloud_per(eng_classified)\n",
    "        else:\n",
    "            cloud_per(tgl_classified)\n",
    "            \n",
    "\n",
    "def changes(change):\n",
    "    with bar:\n",
    "        bar.clear_output()\n",
    "        if lang.value ==  'English':\n",
    "            bar_graph(eng_classified)\n",
    "        else:\n",
    "            bar_graph(tgl_classified)\n",
    "            \n",
    "#add output for bar graph            \n",
    "button_send.on_click(on_button_clicked)\n",
    "vbox_result = widgets.VBox([button_send, output])\n",
    "lang.observe(changed, 'value')\n",
    "lang.observe(changes, 'value')\n",
    "vbox_result2 = widgets.VBox([cloud])\n",
    "vbox_result3 = widgets.VBox([bar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".ins_bg{\n",
       "    background-color:#9CC3D5FF;\n",
       "}\n",
       ".box_style{\n",
       "    background-color:#0063B2FF;\n",
       "    margin: 0px;\n",
       "    width: 100%;\n",
       "    height: 100%;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".ins_bg{\n",
    "    background-color:#9CC3D5FF;\n",
    "}\n",
    ".box_style{\n",
    "    background-color:#0063B2FF;\n",
    "    margin: 0px;\n",
    "    width: 100%;\n",
    "    height: 100%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked right hand side\n",
    "\n",
    "text_0 = widgets.HTML(value=\"<h1>Welcome to SAT comment classifier</h1>\")\n",
    "text_1 = widgets.HTML(value=\"<h2>Upload comments here </h2>\")\n",
    "text_2= widgets.HTML(value=\"<h2>Press button to classify </h2>\")\n",
    "text_3= widgets.HTML(value=\"<h2>Comment Languages </h2>\")\n",
    "text_4= widgets.HTML(value=\"<h2>Analysis</h2>\")\n",
    "\n",
    "vbox_text = widgets.VBox([text_0, text_1, file,text_2, vbox_result, text_3, lang, vbox_result2, text_4, vbox_result3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4860776a2b6648a89e2d1ae85e54a978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xfaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "box_layout = widgets.Layout(display='flex',\n",
    "                flex_flow='column',\n",
    "                align_items='center',\n",
    "                justify_content = 'center',\n",
    "                max_width = \"70%\",\n",
    "                max_height = \"80%\")\n",
    "page = widgets.VBox([vbox_headline, vbox_text],layout=box_layout)\n",
    "page.add_class(\"ins_bg\")\n",
    "hBox = widgets.HBox([page], layout=Layout(display='flex',justify_content = 'center', width='auto', height='auto'))\n",
    "hBox.add_class(\"box_style\")\n",
    "hBox.layout.width = 'auto'\n",
    "display(hBox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
